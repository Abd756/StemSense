# StemSense: AI Audio Analysis & Separation Workflow

This document outlines the architecture, tools, and implementation plan for **StemSense**, a Python-based workflow that fetches audio from YouTube (via URL or Search), separates it into stems (Vocals, Drums, Bass, Other), analyzes musical metadata (BPM, Key, Loudness), and packages the results.

## System Architecture

```mermaid
graph TD
    A[User Input: Song Name or YouTube URL] --> B[YouTube Downloader Engine]
    B -->|Audio File: MP3/WAV| C[ML Stem Separator]
    C -->|Vocals, Drums, Bass, Other| D[Audio Analysis Engine]
    D -->|BPM, Key, Loudness| E[Data Aggregator]
    E --> F[Packaging Engine]
    F -->|ZIP: Original + Stems + JSON Metadata| G[Final Output]
```

## Project Structure

```text
StemSense/
├── main.py                 # Orchestrator (CLI Application)
├── config.py               # Constants, Paths, and Model Configs
├── core/                   # Processing logic
│   ├── __init__.py
│   ├── downloader.py       # Module 1: YouTube Downloader (yt-dlp based)
│   ├── stems.py            # Module 2: ML Stem Separator (Demucs)
│   ├── analyzer.py         # Module 3: Audio Feature Extractor
│   └── packager.py         # Module 4: ZIP Packager
├── tests/                  # Unit and integration tests
├── data/                   # Temporary file storage (ignored by git)
│   ├── downloads/
│   ├── stems/
│   └── exports/
├── requirements.txt
├── .gitignore
└── .env
```

## Modular Implementation Plan

### [Module 1] Audio Downloader (`core/downloader.py`)
*   **Action**: Accept a YouTube URL or a Song Name string. Use `yt-dlp` to search and download the high-quality audio file.
*   **Metadata Extraction**: Capture basic YouTube metadata (Title, Uploader, Duration) to seed the analysis.
*   **Test Case**: Verify that providing a song name results in a valid audio file in `data/downloads/`.

### [Module 2] ML Stem Separator (`core/stems.py`)
*   **Action**: Use **Demucs** (Meta Research) to split the audio into 4 stems: Vocals, Drums, Bass, and Other.
*   **Test Case**: Verify existing output directories for each stem and ensure WAV files are generated.

### [Module 3] Audio Feature Analyzer (`core/analyzer.py`)
*   **Action**: Analyze the original audio file to detect:
    *   **BPM**: Beats per minute.
    *   **Musical Key**: (e.g., C Minor, G Major).
    *   **Loudness**: Integrated LUFS/RMS.
*   **Test Case**: Compare results with known track data for accuracy.

### [Module 4] Packaging & Orchestration (`core/packager.py` & `main.py`)
*   **Action**: Collect all generated files and metadata, create a `metadata.json`, and bundle everything into a timestamped ZIP file.
*   **Test Case**: Ensure the final ZIP contains: `original.mp3`, `vocals.wav`, `drums.wav`, `bass.wav`, `other.wav`, and `metadata.json`.

---

## Technical Considerations

> [!IMPORTANT]
> **FFmpeg**: Must be globally installed and accessible for audio conversion and processing.

> [!NOTE]
> **GPU Support**: Demucs runs significantly faster if a CUDA-enabled GPU is available.

---

## Next Steps

1. **Update Requirements**: Swap Spotify-specific libraries for `yt-dlp`.
2. **Implement Downloader**: Build the search-and-download logic.
3. **Verify Pipeline**: Run a full end-to-end test from URL to ZIP.
